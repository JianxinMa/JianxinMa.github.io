<meta name="description" content="Jianxin Ma (马坚鑫)">
<link rel="stylesheet" href="jemdoc.css" type="text/css">
<title>Jianxin Ma (马坚鑫)</title>

<body>
<div id="layout-content" style="margin-top:25px">

<table>
    <tbody>
        <tr>
            <td width="670">
                <div id="toptitle">
                    <h1>Jianxin Ma &nbsp; <img src="majx_chinesename.jpg" height="36px" style="margin-bottom:-5px" alt=''></h1>
                </div>
                <!-- <h3>Staff Engineer, Alibaba Group</h3> -->
                <p>
                    <!-- Location: Hangzhou, China<br> -->
                    Email: majx13fromthu &alpha;t gmail d&omicron;t com<br>
                </p>
            </td>
            <td>
                <img src="./majx_photo.jpg" border="0" width="200">
            </td>
        </tr>
    </tbody>
</table>

<h2>Biography</h2>
<p>
    <ul>
        <li>
            Prior to December 2024, Jianxin Ma (马坚鑫) was doing research and engineering work on foundation models within the Qwen Team (通义千问-基础大模型), which was previously referred to as the M6 & OFA Team, at Alibaba Group (阿里巴巴).
        </li>
        <li>
            He earned his Master's degree in Computer Science and Technology in June 2020 from Tsinghua University (清华大学), having also obtained his Bachelor's degree in the same field in June 2017 from the same university.
            During his postgraduate studies, he conducted research under the supervision of Wenwu Zhu and Peng Cui, focusing on the development of generative, interpretable, and controllable AI techniques for structured data.
        </li>
    </ul>

</p>

<h2>Research Interests</h2>
<p>
    Building AI systems capable of interacting with the complex world (e.g., structured and multimodal signals) and learning from the collected experiences (e.g., memory, active learning, experiential learning, and automated training data collection).
</p>

<h2>Selected Publications (See <a href="https://scholar.google.com/citations?user=WdDFFlIAAAAJ&hl=en">Google Scholar</a> for Full Publications)</h2>
<ul>
    <li>
        <a href="https://arxiv.org/abs/2407.10671">Qwen2 Technical Report</a>. 2024. <a href="https://github.com/QwenLM">[model]</a>
    </li>
    <li>
        <a href="https://github.com/QwenLM/Qwen-Agent">Qwen-Agent</a>. 2024. <a href="https://github.com/QwenLM/Qwen-Agent">[code]</a>
    </li>
    <li>
        <a href="https://arxiv.org/abs/2309.16609">Qwen Technical Report</a>. 2023. <a href="https://github.com/QwenLM">[model]</a>
    </li>
    <li>
        <a href="https://arxiv.org/abs/2212.02837">Pretrained Diffusion Models for Unified Human Motion Synthesis</a>. 2022.
    </li>
    <li>
        <a href="https://arxiv.org/abs/2202.03052">OFA: Unifying Architectures, Tasks, and Modalities through a Simple Sequence-to-Sequence Learning Framework</a>. ICML 2022. <a href="https://github.com/OFA-Sys/OFA">[code]</a>
    </li>
    <li>
        <a href="https://arxiv.org/abs/2205.08084">M6-Rec: Generative Pretrained Language Models are Open-Ended Recommender Systems</a>. 2022.
    </li>
    <li>
        <a href="https://arxiv.org/abs/2105.14211">M6-UFC: Unifying Multi-Modal Controls for Conditional Image Synthesis via Non-Autoregressive Generative Transformers</a>. NeurIPS 2021.
    </li>
    <li>
        <a href="https://arxiv.org/abs/2103.00823">M6: A Chinese Multimodal Pretrainer</a>. 2021.
    </li>
    <li>
        <a href="https://arxiv.org/abs/2005.12964">Contrastive Learning for Debiased Candidate Generation in Large-Scale Recommender Systems</a>. KDD 2021. <a href="https://github.com/JianxinMa/clrec_v1.0">[code]</a>
    </li>
    <li>
        <a href="http://pengcui.thumedialab.com/papers/DisentangledSequentialRecommendation.pdf">Disentangled Self-Supervision in Sequential Recommenders</a>. KDD 2020.
    </li>
    <li>
        <a href="assets/disentangle-recsys.pdf">Learning Disentangled Representations for Recommendation</a>. NeurIPS 2019. <a href="assets/disentangle-recsys-poster.pdf">[poster]</a> <a href="disentangle-recsys.html">[code & dataset]</a>
    </li>
    <li>
        <a href="assets/DisenGCN.pdf">Disentangled Graph Convolutional Networks</a>. ICML 2019. <a href="assets/DisenGCN-py3.zip">[code]</a>
    </li>
    <li>
        <a href="assets/NetHiex.pdf">Hierarchical Taxonomy Aware Network Embedding</a>. KDD 2018. <a href="assets/nethiex-linux.zip">[code]</a>
    </li>
    <li>
       <a href="assets/DepthLGP.pdf">DepthLGP: Learning Embeddings of Out-of-Sample Nodes in Dynamic Networks</a>. AAAI 2018. <a href="assets/DepthLGPv1.tar.xz">[code]</a><a href="assets/DepthLGP-supp.pdf">[supp]</a>
    </li>
</ul>

<div id="footer">
    <div id="footer-text"></div>
</div>

</div>

Last updated on December 15th, 2024.
</body></html>
